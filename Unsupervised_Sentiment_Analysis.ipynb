{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/punkmic/unsupervised-Sentiment-Analysis---Comparisen-analysis/blob/master/Unsupervised_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXD6WQspxJWc"
      },
      "source": [
        "# **Intro**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-593AM2lxMMh"
      },
      "source": [
        "## **Install Dependecies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7gQcM_NxE2w"
      },
      "outputs": [],
      "source": [
        "# install dependecies here\n",
        "!pip install langdetect  # for language detection\n",
        "!pip install diagrams # for visualize the workflow\n",
        "!pip install graphviz # for visualize the workflow\n",
        "!pip install textblob # for unsupervised sentiment analysis\n",
        "!pip install wordcloud # for wordcloud plot\n",
        "!pip install matplotlib # for plot\n",
        "!pip install PIL # for image manipulation\n",
        "!pip install nltk # for natural language prepocessing\n",
        "!pip install enelvo # for fix slangs, abbreviations, spelling errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rkydqr0uxUiB"
      },
      "source": [
        "## **Load Depencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km0RDHK_xX8V"
      },
      "outputs": [],
      "source": [
        "# load dependecies here\n",
        "from langdetect import detect as dt\n",
        "from diagrams import Diagram as dg\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os \n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0cdDKUrxsq1"
      },
      "source": [
        "## **Load Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Clone Github repository** "
      ],
      "metadata": {
        "id": "SdXyTWtNhrU1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzdi7uwrx8Ls"
      },
      "outputs": [],
      "source": [
        "# Files cloned from github may not automatically appear in files tab in this case right click and choose update\n",
        "# this will update our files.\n",
        "!git clone https://github.com/punkmic/unsupervised-Sentiment-Analysis---Comparisen-analysis.git\n",
        "%cd /content/unsupervised-Sentiment-Analysis---Comparisen-analysis\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git pull "
      ],
      "metadata": {
        "id": "Z9_q4bS6laSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load csv file**"
      ],
      "metadata": {
        "id": "PCZ8r-JXh2FZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_CSV = '/content/unsupervised-Sentiment-Analysis---Comparisen-analysis/results/web_scraping_results.csv'\n",
        "df = pd.read_csv(PATH_TO_CSV, encoding='utf-8')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "xLkm22-Ph6_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Plot some statistics of text**"
      ],
      "metadata": {
        "id": "t6oMhx4pkmU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "bFQkBO-KkVb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Plot wordcloud**"
      ],
      "metadata": {
        "id": "5R_DJGXHnZhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
      ],
      "metadata": {
        "id": "ougKX8fd02-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print currently directory\n",
        "!pwd"
      ],
      "metadata": {
        "id": "IGBXVhu1vK5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new directory for wordclouds\n",
        "wordclouds = '/content/unsupervised-Sentiment-Analysis---Comparisen-analysis/results/wordclouds/'\n",
        "!mkdir wordclouds"
      ],
      "metadata": {
        "id": "QNIgRpoyrXvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and generate a word cloud image:\n",
        "text = str(df['title']).lower()\n",
        "wordcloud = WordCloud(max_font_size=50, max_words=100,  stopwords=STOPWORDS).generate(text)\n",
        "\n",
        "# Save wordcloud \n",
        "wordcloud.to_file('wordclouds/title_wordcloud.png')\n",
        "\n",
        "# Display wordcloud\n",
        "plt.figure()\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "KKtysdp8mLBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create and generate a word cloud image:\n",
        "text = str(df['body']).lower()\n",
        "wordcloud = WordCloud(max_font_size=50, max_words=100).generate(text)\n",
        "\n",
        "# Save wordcloud \n",
        "wordcloud.to_file('wordclouds/body_wordcloud.png')\n",
        "\n",
        "# Display wordcloud\n",
        "plt.figure()\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "BDpeZcXDp5A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvlnEo8NT5mW"
      },
      "source": [
        "## **Text Pre-Processing**\n",
        "\n",
        "Guide\n",
        "* Lower Case conversion\n",
        "* Removing Punctuations\n",
        "* Stop Words Removal\n",
        "* Rare Words Removal\n",
        "* Spelling correction\n",
        "* Tokenization\n",
        "* Lemmatization\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tokenizing**"
      ],
      "metadata": {
        "id": "LqkDwtDlzywC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "# download stop words\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "_G6fWcN70jqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to lowercase and split to a list of words\n",
        "body = ''.join(review for review in df['body'])\n",
        "tokens = word_tokenize(body.lower())\n",
        "filtered_tokens = [token for token in tokens if token not in string.punctuation]\n",
        "filtered_tokens[1:10]"
      ],
      "metadata": {
        "id": "BktL1_Taz1MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Remove stop words**"
      ],
      "metadata": {
        "id": "apKEdeOWM5aM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words\n",
        "# Print the list of available languages\n",
        "portuguese_stop_words = stopwords.words('portuguese')\n",
        "tokens_wo_stop_words = [word for word in filtered_tokens if word not in portuguese_stop_words]\n",
        "tokens_wo_stop_words[1:10]"
      ],
      "metadata": {
        "id": "KJdIkZLmM8IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Word Stemming**"
      ],
      "metadata": {
        "id": "Q8SAwPUl9VCk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjlLrq9mT8et"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use SnowballStemmer stemmer optionally nltk RSLPStemmer for portuguese text language\n",
        "# Initialize stemmer with portuguese\n",
        "stemmer = SnowballStemmer('portuguese') \n",
        "# Stem the words\n",
        "stemmed_words = [stemmer.stem(word) for word in tokens_wo_stop_words]\n",
        "stemmed_words[1:10]"
      ],
      "metadata": {
        "id": "0gL5dhBa9kwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Using enevol to increase performance Maybe ?**"
      ],
      "metadata": {
        "id": "hEPHeZS2-5Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from enelvo.normaliser import Normaliser"
      ],
      "metadata": {
        "id": "IDvas-TC_Azg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm = Normaliser(tokenizer='readable', sanitize=True)"
      ],
      "metadata": {
        "id": "MHIwj7V8AAE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Texblob**"
      ],
      "metadata": {
        "id": "JwHAzXHs_bj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "Qc-jhVX2_fIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sid = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "xfpTn8qmIhO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_blob_sentiment(sentence):\n",
        "  blob = TextBlob(sentence).sentiment\n",
        "  return blob.polarity"
      ],
      "metadata": {
        "id": "qJLW4tDG_5Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Vader**"
      ],
      "metadata": {
        "id": "L5z5Tr7FIKBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "GBONwIhIILyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vader_sentiment(sentence):\n",
        "  vader = sid.polarity_scores(sentence)\n",
        "  return vader['compound']"
      ],
      "metadata": {
        "id": "FTBht6U6I9YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['TextBlob'] = df['body'].apply(lambda sentence: get_blob_sentiment(sentence))\n",
        "df['Vader'] = df['body'].apply(lambda sentence: get_vader_sentiment(sentence))"
      ],
      "metadata": {
        "id": "vUoKYgeGJWiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A negative sentiment score means \n",
        "negative sentiment, and a positive sentiment score means positive sentiment. The higher \n",
        "the absolute value of the score, the more confident the system is about it"
      ],
      "metadata": {
        "id": "vT8dYlRQLD1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "wvpqU7r1K9Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Clustering sentences with K-Means**"
      ],
      "metadata": {
        "id": "fKOeVmUlL08M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.probability import FreqDist\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "q4q2KdkXL83B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get train and test \n",
        "(train, test) = train_test_split()"
      ],
      "metadata": {
        "id": "oFapDjXcN8_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zANBqSOtNerU"
      },
      "source": [
        "## **Save Models to Google Cloud Storage**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ_BMRXENmIi"
      },
      "outputs": [],
      "source": [
        "# import google cloud dependencies\n",
        "from google.colab import auth\n",
        "import uuid # for generate a unique identification for google bucket\n",
        "# Define a project id in google cloud\n",
        "project_id = '<project_ID>'\n",
        "\n",
        "auth.authenticate_user()\n",
        "# configure gsutil\n",
        "## !gcloud config set project {project_id}\n",
        "# set bucket name\n",
        "##backet_name = f'sample-bucket-{uuid.uuid1()}'\n",
        "## !gsuit mb gs://{bucket_name}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0srGkyyiPHEq"
      },
      "outputs": [],
      "source": [
        "# upload model to Google Cloud Storage\n",
        "!gsuit cp /tmp/name_of_file.txt gs://{bucket_name}/\n",
        "\n",
        "# location of model\n",
        "download_location = f\"https://console.cloud.google.com/storage/browser?project={project_id}\"\n",
        "\n",
        "# donwload model from Google Cloud Storage\n",
        "!gsuit cp gs://{bucket_name}/{filename} {download_location}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sStwWfuAzGZ3"
      },
      "source": [
        "## **References**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UcEjjp6F266"
      },
      "source": [
        "[LangDetect](https://pypi.org/project/langdetect/) <br/>\n",
        "[Diagrams](https://pypi.org/project/diagrams/) <br/>\n",
        "[Graphviz](https://pypi.org/project/graphviz/) <br/>\n",
        "[Beautifulsoap4](https://pypi.org/project/beautifulsoup4/) <br/>\n",
        "[OpLexicon](https://www.inf.pucrs.br/linatural/wordpress/recursos-e-ferramentas/oplexicon/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('.env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "6870af64cccb2dc4285885e4363d49c25adb22669b810ecb9f48ab42b19689bd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}