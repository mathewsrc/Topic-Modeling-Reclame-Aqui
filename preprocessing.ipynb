{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/punkmic/Topic-Modeling-Reclame-Aqui/blob/master/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre-Processing** "
      ],
      "metadata": {
        "id": "y2QxkuH89sQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setup**"
      ],
      "metadata": {
        "id": "eXD8VBix7DD1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ0hDdDm6gtj",
        "outputId": "43191fbd-c941-4e7f-ef0f-f7732fa68879",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd # for data manipulation\n",
        "import os # for interacting with the operating system\n",
        "import nltk # for natural language processing\n",
        "import string # for string manipulation \n",
        "import re # for for regular expressions\n",
        "import matplotlib.pyplot as plt # for visualization\n",
        "import spacy # for lemmatize portuguese text\n",
        "import pickle\n",
        "try:\n",
        "  from spellchecker import SpellChecker # for spell check\n",
        "except:\n",
        "  !pip install pyspellchecker\n",
        "  os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Install spacy pt_core_news_sm for portuguese text\n",
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "id": "dafLrQKmvlGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "id": "BvRCi7Cvp0G6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff8801b0-c3fd-4968-f138-960f9dde6888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset with stopwords\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "id": "JAvaPg5ep3Df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc0e1a7-8d9c-4c62-da4d-e4aa10363908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Donwload datasets for lemmatization\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "97RrmPshvcmu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c99a4630-bb68-44d2-a428-cc1c8008a622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Donwload dependency need to stem portuguese text\n",
        "nltk.download('rslp')"
      ],
      "metadata": {
        "id": "qn9OrF3EXCNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4970984a-efb0-4883-df90-af48318c10ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load data from [Github](https://github.com/punkmic/Topic-Modeling-Reclame-Aqui.git)**"
      ],
      "metadata": {
        "id": "EGjKdT4C8RVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/punkmic/Topic-Modeling-Reclame-Aqui.git"
      ],
      "metadata": {
        "id": "C_yss1JC-8Ou",
        "outputId": "937a7dec-c6ae-49b3-d5a3-a66d7997ec66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Topic-Modeling-Reclame-Aqui'...\n",
            "remote: Enumerating objects: 16196, done.\u001b[K\n",
            "remote: Counting objects: 100% (2015/2015), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1763/1763), done.\u001b[K\n",
            "remote: Total 16196 (delta 257), reused 1916 (delta 222), pack-reused 14181\u001b[K\n",
            "Receiving objects: 100% (16196/16196), 117.72 MiB | 21.07 MiB/s, done.\n",
            "Resolving deltas: 100% (1405/1405), done.\n",
            "Checking out files: 100% (14806/14806), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "id": "LQhdM4NR0yss",
        "outputId": "386ab98b-a332-449b-f7dc-3f03e85e23ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Topic-Modeling-Reclame-Aqui'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory\n",
        "%cd /content/Topic-Modeling-Reclame-Aqui \n",
        "\n",
        "# Update files from remote repository\n",
        "!git pull \n",
        "\n",
        "# Return to work directory\n",
        "%cd ..\n",
        "\n",
        "# Check current directory\n",
        "!pwd"
      ],
      "metadata": {
        "id": "uv3QBnDRHFPv",
        "outputId": "44a957d1-02a8-4369-d34b-c756ce1fa5d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Topic-Modeling-Reclame-Aqui\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "From https://github.com/punkmic/Topic-Modeling-Reclame-Aqui\n",
            "   3c52906..83eaeea  master     -> origin/master\n",
            "There is no tracking information for the current branch.\n",
            "Please specify which branch you want to merge with.\n",
            "See git-pull(1) for details.\n",
            "\n",
            "    git pull <remote> <branch>\n",
            "\n",
            "If you wish to set tracking information for this branch you can do so with:\n",
            "\n",
            "    git branch --set-upstream-to=origin/<branch> master\n",
            "\n",
            "/content\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prepare data**"
      ],
      "metadata": {
        "id": "5YitWNVVJTOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(path_csv, drop_duplicates = True, lower=True):\n",
        " \n",
        "  # Use the read_csv method to read csv file\n",
        "  df = pd.read_csv(path_csv)\n",
        "  \n",
        "  if drop_duplicates:\n",
        "    # Read and return the CSV file using the read_csv method\n",
        "    print(f\"Shape before remove duplicates: {df.shape}\")\n",
        "\n",
        "    # Use the drop_duplicated method to drop duplicates rows\n",
        "    df = df.drop_duplicates(subset=\"text\")\n",
        "\n",
        "    print(f\"Shape after remove duplicates: {df.shape}\")\n",
        "\n",
        "    if lower:\n",
        "      # apply the str.lower() method to each element in the dataframe\n",
        "      df = df.applymap(str.lower)\n",
        "  return df"
      ],
      "metadata": {
        "id": "F3IoOKARBwVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to data\n",
        "path_csv = \"/content/Topic-Modeling-Reclame-Aqui/corpus.csv\"\n",
        "\n",
        "df = read_data(path_csv)\n",
        "\n",
        "# Print the first 5 rows of the DataFrame\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "2ppvYJG90iVk",
        "outputId": "4c31d394-7767-4659-e72b-845a63ae8cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before remove duplicates: (12760, 2)\n",
            "Shape after remove duplicates: (10510, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  pedido cancelado sem justificativa após uma se...   \n",
              "1                                  pedido cancelado    \n",
              "2                                  cobrança indevida   \n",
              "3                                 pedido reincidente   \n",
              "4            assinatura para vender na amazon brasil   \n",
              "\n",
              "                                                text  \n",
              "0  eu estava pesquisando bastante uma nova tv par...  \n",
              "1  eu sinceramente estou decepcionada com o amazo...  \n",
              "2  cancelei meu plano antes de terminar o período...  \n",
              "3  olha fiz compra veio errada, e veio errado nov...  \n",
              "4  eu me inscrevi na amazon para realizar vendas ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4953d9df-e577-4302-85d2-a6ae871d941d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pedido cancelado sem justificativa após uma se...</td>\n",
              "      <td>eu estava pesquisando bastante uma nova tv par...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pedido cancelado</td>\n",
              "      <td>eu sinceramente estou decepcionada com o amazo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cobrança indevida</td>\n",
              "      <td>cancelei meu plano antes de terminar o período...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pedido reincidente</td>\n",
              "      <td>olha fiz compra veio errada, e veio errado nov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>assinatura para vender na amazon brasil</td>\n",
              "      <td>eu me inscrevi na amazon para realizar vendas ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4953d9df-e577-4302-85d2-a6ae871d941d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4953d9df-e577-4302-85d2-a6ae871d941d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4953d9df-e577-4302-85d2-a6ae871d941d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset contains just two columns called title and text "
      ],
      "metadata": {
        "id": "gDfB_6inJgr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)"
      ],
      "metadata": {
        "id": "Ytly9hiGJzFA",
        "outputId": "525bf113-55d4-47bc-8ed1-887fb5193938",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10510, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 10510 unique rows in this dataset."
      ],
      "metadata": {
        "id": "Upvg5pKOJ0bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# join columns\n",
        "df[\"documents\"] = df[\"title\"] + \" \" + df[\"text\"]\n",
        "\n",
        "# Use the replace() method to replace the string with an empty string\n",
        "df = df.replace(re.compile('\\[editado pelo reclame aqui\\]|editado pelo reclame aqui|Editado pelo Reclame Aqui'), '')\n",
        "\n",
        "# Drop the old index column\n",
        "df.reset_index(inplace = True, drop = True)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "N0iqgleUNVlE",
        "outputId": "3e90d13c-e8f9-46a5-c3cf-d58e62dbd8c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  pedido cancelado sem justificativa após uma se...   \n",
              "1                                  pedido cancelado    \n",
              "2                                  cobrança indevida   \n",
              "3                                 pedido reincidente   \n",
              "4            assinatura para vender na amazon brasil   \n",
              "\n",
              "                                                text  \\\n",
              "0  eu estava pesquisando bastante uma nova tv par...   \n",
              "1  eu sinceramente estou decepcionada com o amazo...   \n",
              "2  cancelei meu plano antes de terminar o período...   \n",
              "3  olha fiz compra veio errada, e veio errado nov...   \n",
              "4  eu me inscrevi na amazon para realizar vendas ...   \n",
              "\n",
              "                                           documents  \n",
              "0  pedido cancelado sem justificativa após uma se...  \n",
              "1  pedido cancelado  eu sinceramente estou decepc...  \n",
              "2  cobrança indevida cancelei meu plano antes de ...  \n",
              "3  pedido reincidente olha fiz compra veio errada...  \n",
              "4  assinatura para vender na amazon brasil eu me ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1618e8be-7046-4f1e-ae38-2f6deb0c6d5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>documents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pedido cancelado sem justificativa após uma se...</td>\n",
              "      <td>eu estava pesquisando bastante uma nova tv par...</td>\n",
              "      <td>pedido cancelado sem justificativa após uma se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pedido cancelado</td>\n",
              "      <td>eu sinceramente estou decepcionada com o amazo...</td>\n",
              "      <td>pedido cancelado  eu sinceramente estou decepc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cobrança indevida</td>\n",
              "      <td>cancelei meu plano antes de terminar o período...</td>\n",
              "      <td>cobrança indevida cancelei meu plano antes de ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pedido reincidente</td>\n",
              "      <td>olha fiz compra veio errada, e veio errado nov...</td>\n",
              "      <td>pedido reincidente olha fiz compra veio errada...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>assinatura para vender na amazon brasil</td>\n",
              "      <td>eu me inscrevi na amazon para realizar vendas ...</td>\n",
              "      <td>assinatura para vender na amazon brasil eu me ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1618e8be-7046-4f1e-ae38-2f6deb0c6d5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1618e8be-7046-4f1e-ae38-2f6deb0c6d5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1618e8be-7046-4f1e-ae38-2f6deb0c6d5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Save table as image**"
      ],
      "metadata": {
        "id": "J5KS9IgNbqGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to save \n",
        "path = '/content/Topic-Modeling-Reclame-Aqui/results/joined_table/'\n",
        "\n",
        "# Use makedirs() to create a new directory if it does not exists\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.head(10).to_csv(path + 'joined_table.csv')"
      ],
      "metadata": {
        "id": "ziN54QGkbtk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preprocessing**"
      ],
      "metadata": {
        "id": "drjuwA5yk4YB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Tokenization**\n",
        "\n",
        "Tokenization aims to breaking text down into its component parts"
      ],
      "metadata": {
        "id": "i9ukWCy8qBOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WORD_TOKENIZER = nltk.tokenize.word_tokenize\n",
        "def tokenize(text, lowercase=True):\n",
        "  if lowercase:\n",
        "    text = text.lower()\n",
        "  return WORD_TOKENIZER(text, language=\"portuguese\")"
      ],
      "metadata": {
        "id": "k_f8hsxJk7v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Stem** \n",
        "\n",
        "Stem the tokens. This step aims to remove morphological affixes and normalize to standardized stem forms"
      ],
      "metadata": {
        "id": "Lm7V--yMq98r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STEMMER = nltk.stem.RSLPStemmer()\n",
        "def stem(tokens):\n",
        "  return [STEMMER.stem(token) for token in tokens]"
      ],
      "metadata": {
        "id": "TphgFQIxrPMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Lemmatize**\n",
        "\n",
        "Lemmatize the tokens. Retains more natural forms than stemming, but assumes all tokens nons unless tokens are passed as (word, pos) tuples. Note: nltk lemmatize does not suport portugues language"
      ],
      "metadata": {
        "id": "RTiUcqzrrdiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LEMMATIZER = nltk.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize(tokens):\n",
        "  lemmas = []\n",
        "  for token in tokens:\n",
        "      if isinstance(token, str):\n",
        "          # treats token like a noun\n",
        "          lemmas.append(LEMMATIZER.lemmatize(token)) \n",
        "      else: \n",
        "          # assume a tuple of (word, pos)\n",
        "          lemmas.append(LEMMATIZER.lemmatize(*token))\n",
        "  return lemmas"
      ],
      "metadata": {
        "id": "4O48ihphrxy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmatize option for portuguese text**"
      ],
      "metadata": {
        "id": "eHdBPARlU24i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_pt(tokens, nlp):\n",
        "  # Create a spaCy Doc object and apply the lemmatization\n",
        "  doc = nlp(' '.join(tokens))\n",
        "\n",
        "  # Return lemmatize\n",
        "  return [token.lemma_ for token in doc]"
      ],
      "metadata": {
        "id": "pfgdVUHVU6Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Remove stopwords**\n",
        "\n",
        "Stop words are things like articles and conjunctions that usually do not offer a lot of value in an analysis."
      ],
      "metadata": {
        "id": "jkLYqJgDs4Xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(tokens, stopwords=None):\n",
        "\n",
        "  # Use the default stop words if none is passed\n",
        "  if stopwords is None:\n",
        "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "  \n",
        "  # Filter the list of tokens to exclude the stop word tokens\n",
        "  return [token for token in tokens if token not in stopwords]"
      ],
      "metadata": {
        "id": "D9blZaBYtHgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Remove hyperlinks**\n",
        "\n",
        "Removes http/s links from the tokens."
      ],
      "metadata": {
        "id": "X4qMKyfKtaAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_links(tokens):\n",
        "  # Filter tokens that starts with \"http://\" or \"https://\"\n",
        "  return [token for token in tokens \n",
        "          if not token.startswith(\"http://\")\n",
        "          and not token.startswith(\"https://\")]"
      ],
      "metadata": {
        "id": "LqlMta5qtovS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Remove numbers**"
      ],
      "metadata": {
        "id": "EwKFluprz-pW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_numbers(tokens):\n",
        "  # Filter out number tokens using a list comprehension and the isnumeric method\n",
        "  return [token for token in tokens if not token.isnumeric()]\n"
      ],
      "metadata": {
        "id": "ALKnXv8C0EWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Remove date**"
      ],
      "metadata": {
        "id": "a0pZKAQ7ZJHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_date(tokens):\n",
        "  # Compile a regular expression to match dates in the format dd/mm or dd/mm/yyyy\n",
        "  date_regex = re.compile(r'\\d{2}/\\d{2}(/\\d{4})?')\n",
        "\n",
        "  # Use the regex to find all the tokens that match the date pattern\n",
        "  dates = [token for token in tokens if date_regex.fullmatch(token)]\n",
        "\n",
        "  # Filter the list of tokens to exclude the date tokens\n",
        "  filtered_tokens = [token for token in tokens if token not in dates]\n",
        "\n",
        "  # Return the filtered tokens\n",
        "  return filtered_tokens"
      ],
      "metadata": {
        "id": "ywykIjKZctc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Remove punctuation**"
      ],
      "metadata": {
        "id": "7y1FqCD1t75_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(tokens,\n",
        "                       strip_mentions=False,\n",
        "                       strip_hashtags=False,\n",
        "                       strict=False):\n",
        "\n",
        "    # Use a regular expression to match and remove repeated punctuation characters\n",
        "    tokens = [re.sub(r\"([!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~])\\1+\", \"\", token) for token in tokens]\n",
        "\n",
        "    # Filter punctuation tokens\n",
        "    tokens = [token for token in tokens if token not in string.punctuation]\n",
        "\n",
        "    # Remove @ symbol from left side of tokens\n",
        "    if strip_mentions:\n",
        "        tokens = [t.lstrip('@') for t in tokens]\n",
        "\n",
        "    # Remove # symbol from left side of tokens\n",
        "    if strip_hashtags:\n",
        "        tokens = [t.lstrip('#') for t in tokens]\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "ba7paG7_uBtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Remove short tokens**"
      ],
      "metadata": {
        "id": "SiUx2T8C5YBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_short_tokens(tokens):\n",
        "  # Filter the list of tokens to exclude tokens that are shorter than four letters\n",
        "  filtered_tokens = [token for token in tokens if len(token) >= 4]\n",
        "\n",
        "  # Return the filtered tokens\n",
        "  return filtered_tokens"
      ],
      "metadata": {
        "id": "t8SOwNYW6QI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Correction of spelling errors**"
      ],
      "metadata": {
        "id": "WqtOisN38pZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_spell_errors(text, spell):\n",
        "\n",
        "  # Correct the spelling errors in the text\n",
        "  corrected_text = spell.correction(text)\n",
        "\n",
        "  # If no correction is present user the original text\n",
        "  if corrected_text == None:\n",
        "     corrected_text =  text\n",
        "  \n",
        "  # Return the corrected text\n",
        "  return corrected_text"
      ],
      "metadata": {
        "id": "fUTiJYc_8hba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(documents, nlp = None, spell = None):\n",
        "  corpus = []\n",
        "\n",
        "  # process each document and append to corpus list\n",
        "  for i, text in enumerate(documents):\n",
        "    if i % 1000 == 0:\n",
        "      print(f\"{i} documents of {len(documents)}\\n\")\n",
        "    if spell is not None:\n",
        "      text = check_spell_errors(text, spell)\n",
        "    tokens = tokenize(text)\n",
        "    tokens = remove_links(tokens)\n",
        "    tokens = remove_punctuation(tokens, strip_mentions=True, strip_hashtags=True)\n",
        "    tokens = remove_numbers(tokens)\n",
        "    tokens = remove_date(tokens)\n",
        "    tokens = remove_short_tokens(tokens)\n",
        "    tokens = remove_stopwords(tokens)\n",
        "    if nlp is not None: \n",
        "      tokens = lemmatize_pt(tokens, nlp)\n",
        "    #tokens = stem(tokens) \n",
        "    corpus.append(' '.join(tokens))\n",
        "  return corpus"
      ],
      "metadata": {
        "id": "5aiFtbo3uuh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a SpellChecker object\n",
        "spell = SpellChecker(language='pt')\n",
        "\n",
        "nlp = spacy.load('pt_core_news_sm')\n",
        "\n",
        "corpus = preprocessing(df.documents, nlp, spell)"
      ],
      "metadata": {
        "id": "Tu75mPgywHwb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a0379e-9578-415c-b475-2078bd49e4a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 documents of 10510\n",
            "\n",
            "1000 documents of 10510\n",
            "\n",
            "2000 documents of 10510\n",
            "\n",
            "3000 documents of 10510\n",
            "\n",
            "4000 documents of 10510\n",
            "\n",
            "5000 documents of 10510\n",
            "\n",
            "6000 documents of 10510\n",
            "\n",
            "7000 documents of 10510\n",
            "\n",
            "8000 documents of 10510\n",
            "\n",
            "9000 documents of 10510\n",
            "\n",
            "10000 documents of 10510\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first document before and after pre-processing it\n",
        "print(df.documents[0])\n",
        "print()\n",
        "print(corpus[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jmOFKM1M-Qx",
        "outputId": "be2e650b-4844-4c20-8af3-c1215614bada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pedido cancelado sem justificativa após uma semana da compra eu estava pesquisando bastante uma nova tv para comprar e resolvi aguardar a semana do cliente, porque como ocorreu tiveram vários descontos e promoções nessa semana, sendo assim recebi descontos, cashback e cupons de varias plataformas e assim decidi efetuar a compra aquela que eu entendesse ser o melhor custo beneficio. sendo assim no dia 12 de setembro de 2022 recebi uma oferta de produto da amazon que entendi estar com um preço muito bom além de ter cachback e efetuei a compra que já aguardei até a semana do consumidor para efetuar com toda a expectativa. como estavamos anciosos e mesmo estando dentro do prazo de entrega hoje no dia 19/09 resolvi enviar uma mensagem perguntando quando o pedido seria enviado, ja que após a confirmação da compra e pagamento, passado 7 dias não tive nenhum retorno, já que complei inclusive na amazon, um site em que confio e tambem sou assinante. para a minha surpresa após o pedido de informação do pedido, tenho um retorno por email na qual o mesmo estaria sendo cancelado, sendo nenhuma justificativa e após 7 dias da realização do mesmo. ou seja aguardei chegar em um periodo de compro ansiosamente para aproveitar os descontos de um produto que minha familia aguardava, e além de cancelar a compra do produto sem uma justificativa a empresa me tirou todas as oportunidades e descontos que tive de efetuar a compra na semana do consumidor já que levaram 7 dias para cancelar o mesmo, me sinto extremamente  por uma empresa em que sempre acreditei, aguardo uma satisfação e reparação aos meus transtornos sofridos, já que hoje não consigo mais comprar esse produto pelo mesmo valor ou próximo a ele.\n",
            "\n",
            "pedir cancelado justificativa após semana comprr pesquisar bastante novo comprar resolver aguardar semana cliente porque ocorrer vários desconto promoção em esse semana ser assim recebi desconto cashback cupom varia plataforma assim decidir efetuar compra entender melhor custo beneficio ser assim setembro recebi oferta produto amazon entendi preço além cachback efetuei comprar aguardei semana consumidor efetuar todo expectativa estavar ancioso estar dentro prazo entregar hoje resolver enviar mensagem perguntar pedir enviar após confirmação comprar pagamento passado dia nenhum retorno complei inclusive amazon site confio tambem assinante surpresa após pedir informação pedir retorno email estar ser cancelar ser nenhum justificativa após dia realização aguardei chegar periodo compro ansiosamente aproveitar desconto produto familia aguardar além cancelar compra produto justificativa empresa tirar todo oportunidade desconto efetuar compra semano consumidor levar dia cancelar sinto extremamente empresa sempre acreditar aguardo satisfação reparação transtorno sofrer hoje com si comprar produto valor próximo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Save corpus**"
      ],
      "metadata": {
        "id": "R3XrLLNX_sPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "def save_corpus(corpus, file_name=\"corpus.pkl\"):\n",
        "  file_path = f'./corpus/{file_name}'\n",
        "\n",
        "  if not os.path.exists('./corpus'):\n",
        "    os.makedirs('./corpus')\n",
        "  with open(file_path, 'wb') as f:\n",
        "    # Save the DataFrame to the file\n",
        "    pickle.dump(corpus, f)\n"
      ],
      "metadata": {
        "id": "3_c9VgWQBtfI"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "def load_corpus(file_name = \"corpus.pkl\"):\n",
        "  file_path = f'./corpus/{file_name}'\n",
        "  return pickle.load(open(file_path, 'rb'))"
      ],
      "metadata": {
        "id": "DtSWea5AOoOD"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_corpus(\"corpus.pkl\")[:1]"
      ],
      "metadata": {
        "id": "IXCxG5yqH-5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Update github**"
      ],
      "metadata": {
        "id": "B0OffAkLaWJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass"
      ],
      "metadata": {
        "id": "tnvmkYufcoXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Topic-Modeling-Reclame-Aqui/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIttnE7NbUbc",
        "outputId": "120bcdc5-ada7-4b85-dd75-998e52b2861b"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Topic-Modeling-Reclame-Aqui\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muRSKFP0aUMe",
        "outputId": "0e97f1f7-d8dc-4b84-b849-ade09e205349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/Topic-Modeling-Reclame-Aqui/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ."
      ],
      "metadata": {
        "id": "IB4f8adebmTZ"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeXB_SqHcFNN",
        "outputId": "138ab6ae-4bd5-4afc-ffc7-dbceeacfdc51"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch master\n",
            "Changes to be committed:\n",
            "  (use \"git reset HEAD <file>...\" to unstage)\n",
            "\n",
            "\t\u001b[32mnew file:   corpus/corpus.pkl\u001b[m\n",
            "\t\u001b[32mdeleted:    corpus/preprocessed/corpus.p\u001b[m\n",
            "\t\u001b[32mmodified:   load_corpus.py\u001b[m\n",
            "\t\u001b[32mmodified:   save_corpus.py\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\t\u001b[31m__pycache__/click_list_param.cpython-38.pyc\u001b[m\n",
            "\t\u001b[31m__pycache__/load_corpus.cpython-38.pyc\u001b[m\n",
            "\t\u001b[31m__pycache__/save_corpus.cpython-38.pyc\u001b[m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "username = getpass(\"Username: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W908rYRZctaZ",
        "outputId": "e44eeb89-d12b-453b-b8ed-8e017fc6749b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Username: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "email = getpass(\"Email: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIzeWx80cwss",
        "outputId": "4e0bd69c-02bc-4f48-ae8b-574d689367e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Email: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "password = getpass(\"Password: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfGb2sGGfS92",
        "outputId": "d072e38a-c70f-4f19-a146-8e368a9174dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Password: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email username\n",
        "!git config --global user.name email\n",
        "!git config --global user.password password"
      ],
      "metadata": {
        "id": "7uqLrbAzcS2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"Update save_corpus.py and load_corpus.py\"\n",
        "assert message != None"
      ],
      "metadata": {
        "id": "uWjKVNmwkNdi"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdsyZOkpcIvj",
        "outputId": "3038f2e2-8f38-4ec4-e122-afa616eb54cd"
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[master 7f6b06b] message\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = getpass(\"Token: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmvXIRXifv8v",
        "outputId": "cf1e90c5-6b9b-40cf-cca8-4644d44f3a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote rm origin\n",
        "!git remote add origin https://$token@github.com/$username/Topic-Modeling-Reclame-Aqui.git"
      ],
      "metadata": {
        "id": "Q5uWHCGyeU8N"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwMOrkiGeOdH",
        "outputId": "e66e4866-0d2a-4f98-ccc0-c98d7796c740"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counting objects: 8, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (7/7), done.\n",
            "Writing objects: 100% (8/8), 1.25 MiB | 2.67 MiB/s, done.\n",
            "Total 8 (delta 2), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (2/2), completed with 1 local object.\u001b[K\n",
            "To https://github.com/punkmic/Topic-Modeling-Reclame-Aqui.git\n",
            "   83eaeea..7f6b06b  master -> master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "ICp2vgq8l3CH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}