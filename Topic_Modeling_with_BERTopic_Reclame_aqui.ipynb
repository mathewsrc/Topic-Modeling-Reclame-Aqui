{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2b99f011a9645a5a0e9faa6419d8c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94da80bd69574a6fa316bab66c225d27",
              "IPY_MODEL_9e15c73842094ac58a7a494e0c462890",
              "IPY_MODEL_d67f45cbc448493ea434cf334b2cfb82"
            ],
            "layout": "IPY_MODEL_e94efe4842504a4ba102f77c4a593873"
          }
        },
        "94da80bd69574a6fa316bab66c225d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f1666ce94e34e47be1943d4cf46c96e",
            "placeholder": "​",
            "style": "IPY_MODEL_a6243b706f604faebf82290b13ba2f4a",
            "value": "Batches: 100%"
          }
        },
        "9e15c73842094ac58a7a494e0c462890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d2b16b3299c475d82fa6e9d08a55e71",
            "max": 329,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e9eae08fc0249ba863b8c7011d439ec",
            "value": 329
          }
        },
        "d67f45cbc448493ea434cf334b2cfb82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b29e3577236542cab4b26de86d8a0088",
            "placeholder": "​",
            "style": "IPY_MODEL_e745a70d7d664065892e4a4f814d87ea",
            "value": " 329/329 [00:17&lt;00:00, 62.74it/s]"
          }
        },
        "e94efe4842504a4ba102f77c4a593873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f1666ce94e34e47be1943d4cf46c96e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6243b706f604faebf82290b13ba2f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d2b16b3299c475d82fa6e9d08a55e71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e9eae08fc0249ba863b8c7011d439ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b29e3577236542cab4b26de86d8a0088": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e745a70d7d664065892e4a4f814d87ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/punkmic/Topic-Modeling-Reclame-Aqui/blob/master/Topic_Modeling_with_BERTopic_Reclame_aqui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Topic Modeling with BERTopic - Reclame Aqui**\n",
        "\n",
        "BERTopic is a topic modeling technique that leverages transformers and a custom class-based TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions \n",
        "\n",
        "Reference: (https://maartengr.github.io/BERTopic/index.html)."
      ],
      "metadata": {
        "id": "VG5Z-hvZ9GIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Enabling the GPU**\n",
        "\n",
        "We will use the GPU provided by COLAB to accelarate our model training. To enable GPUs for the notebook:\n",
        "1- Navigate to Edit -> Notebook Settings\n",
        "2- Select GPU from the Hardware Accelerator drop-down"
      ],
      "metadata": {
        "id": "W_0vnbvROpuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# verify if GPU is enable\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "gj08UQrDOqW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de358eb-7881-4f01-d47b-16362e5ebe5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 11 14:12:29 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0    28W /  70W |   1550MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setup**"
      ],
      "metadata": {
        "id": "eXD8VBix7DD1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ0hDdDm6gtj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "try:\n",
        "  import pandas as pd # for data manipulation\n",
        "  import os # for interacting with the operating system\n",
        "  import nltk # for natural language processing\n",
        "  import matplotlib.pyplot as plt # for visualization\n",
        "  from bertopic import BERTopic # for topic modeling\n",
        "  import json\n",
        "  import optuna # for hyperparameter optimization\n",
        "  from hdbscan import HDBSCAN # for clustering\n",
        "  from sklearn.cluster import KMeans # for clustering\n",
        "  from umap import UMAP # for dimension reduction\n",
        "  from sklearn.decomposition import PCA # for dimension reduction\n",
        "  from sklearn.feature_extraction.text import CountVectorizer # for convert text documents to matrix of tokens count\n",
        "  from bertopic.vectorizers import ClassTfidfTransformer \n",
        "  import ast # for convert str to tuple\n",
        "  import csv\n",
        "  from gensim import models\n",
        "  from gensim.corpora import Dictionary\n",
        "  from gensim.models.coherencemodel import CoherenceModel\n",
        "  import pickle \n",
        "except:\n",
        "  !pip install bertopic\n",
        "  !pip install kaleido # for save BERTopic plots as image\n",
        "  !pip install optuna\n",
        "  !pip install hdbscan\n",
        "  !pip install umap-learn\n",
        "  !pip install gensim\n",
        "  from gensim import models\n",
        "  from gensim.corpora import Dictionary\n",
        "  from gensim.models.coherencemodel import CoherenceModel\n",
        "  from umap import UMAP # for dimension reduction\n",
        "  import optuna # for hyperparameter optimization\n",
        "  from hdbscan import HDBSCAN # for clustering\n",
        "  from bertopic import BERTopic # for topic modeling\n",
        "  from bertopic.vectorizers import ClassTfidfTransformer "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WORK_DIR = '/content/Topic-Modeling-Reclame-Aqui/'"
      ],
      "metadata": {
        "id": "gm7oJoCxgCHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_FRAME_FEATURE_NAME = 'documents'\n",
        "\n",
        "docs = pd.read_csv('./datasets/raw.csv')\n",
        "print(docs[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdRUWhqa2hB_",
        "outputId": "fac9a3dd-b940-4246-91d1-ff450d10ec67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pesquisando bastante novo comprar resolver aguardar semana cliente porque ocorrer vários desconto promoção em esse semana ser assim recebi desconto cashback cupom varia plataforma assim decidir efetuar compra entender melhor custo beneficio ser assim setembro recebi oferta produto entendi preço além cachback efetuei comprar aguardei semana consumidor efetuar todo expectativa estavar ancioso estar dentro prazo entregar hoje resolver enviar mensagem perguntar pedir enviar após confirmação comprar pagamento passado dia nenhum retorno complei inclusive site confio tambem assinante surpresa após pedir informação pedir retorno email estar ser cancelar ser nenhum justificativa após dia realização aguardei chegar periodo compro ansiosamente aproveitar desconto produto familia aguardar além cancelar compra produto justificativa empresa tirar todo oportunidade desconto efetuar compra semano consumidor levar dia cancelar sinto extremamente empresa sempre acreditar aguardo satisfação reparação transtorno sofrer hoje com si comprar produto valor próximo', 'sinceramente decepcionar entrar contato procon hoje informar marcar audiência conciliação porque amozan responder solicitação esclarecimento procon procon importar fazer somente querer contar produto vender estoque cancelar satisfação algunhar total falta respeito consumidor fazer sair criança recém nascir desistir direito em esse audiência assim', 'cancelei plano antes terminar período testir grátis pois gostar plataforma segundo cobr fatura dois mês assinar contando gratuito caso resolr problema ir entrar processo contra tentar contato onde conversar retornar maisengraçar contratar poder qualquer pessoa precisar ficar vir reclamar outro local respondar agora cancelar nenhum canal atendimento funcionar', 'olhar compra vir errar vir errar novamente falar mariano pensar entendir problema falei escolher desodorante cinca vir verde errar agora vir verde novamente acreditar', 'inscrevi realizar venda Brasil cadastro plano individual cobrar apenas real venda realizar por surpresa conseguir finalizar recebi mensagem nubank realizar pagamento valor dolar real realizei encerramento contar abri afim evitar cobrança por consigo contato saber faço receber reembolsolembrar autorizei interesse plano global vender querer apenas vender brasil pagar plano real vendafico aguardo soluçao', 'pedido chegar cancelar compra site linkr solicitar reembolsosobre devolução dinheiro entregar pedir dar necessita judicial', 'compra xaropurer kaly gengibre status informar entregue acontecer', 'setembro solicitei devolução coleto após algum dia cancelar solicitar novamente presente data reembolsar sabese atendimento chat central saber dizer resolver', 'compra smart loja oficial efacil algum dia pedir cancelar informar pedir cancelar efacil nenhum motivo pedir ser aprovar cartão querer cumprimento ofertar', 'compra echar em esse pude aproveitar promoção site oferecer echo compr prazo grande quase mês previsão primeiro quinzena outubro porém hoje recebi email avisar cancelamento compra primeiro experiência preter outro esperar todo tempo produto demorar avisar cancelamento chancer aproveitar consumidor tiveno prejudicar péssimo experiência']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training a BERTopic Model**\n",
        "\n",
        "The BERTopic algorithm has several advantages over other topic modeling algorithms. It is able to handle sparse data, it is scalable to large datasets, and it is able to learn topics that are not well-defined or are overlapping.\n",
        "\n",
        "As our data language is portuguese we will going to set language to multilingual."
      ],
      "metadata": {
        "id": "AWmOFQ3VOD05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new BERTopic model and train it. By default BERTopic use the paraphrase-multilingual-MiniLM-L12-v2 model for multi language documents. For others model check here [BERTopic sentence transformers](https://maartengr.github.io/BERTopic/getting_started/embeddings/embeddings.html#sentence-transformers)"
      ],
      "metadata": {
        "id": "_mBsnRnhgbm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new BERTopic model using multilingual option\n",
        "topic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True)\n",
        "\n",
        "# Train model \n",
        "topics, probs = topic_model.fit_transform(docs)"
      ],
      "metadata": {
        "id": "B0EFqnutN2Y9",
        "outputId": "08723340-9715-4d39-a2b0-55df62068b04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a2b99f011a9645a5a0e9faa6419d8c59",
            "94da80bd69574a6fa316bab66c225d27",
            "9e15c73842094ac58a7a494e0c462890",
            "d67f45cbc448493ea434cf334b2cfb82",
            "e94efe4842504a4ba102f77c4a593873",
            "1f1666ce94e34e47be1943d4cf46c96e",
            "a6243b706f604faebf82290b13ba2f4a",
            "8d2b16b3299c475d82fa6e9d08a55e71",
            "7e9eae08fc0249ba863b8c7011d439ec",
            "b29e3577236542cab4b26de86d8a0088",
            "e745a70d7d664065892e4a4f814d87ea"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/329 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2b99f011a9645a5a0e9faa6419d8c59"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERTopic works in three main steps: \n",
        "\n",
        "\n",
        "1.   Documents are first converted to numeric data. It extracts different embeddings based on the context of the word. For this, a sentence transformation model is used.\n",
        "2.  Documents with similar topics are then grouped together forming clusters with similar topics. For this purpose, BERTopic uses the clustering algorithm UMAP to lower the dimensionality of the embeddings. Then the documents are clustered with the density-based algorithm HDBSCAN.\n",
        "3. BERTopic extracts topics from clusters using a class-based TF-IDF score. This score gives the importance of each word in a cluster. Topics are then created based on the most important words measured by their C-TF-IDF score.\n",
        "\n",
        "For more information check this link [BERTopic](https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6)\n",
        "\n"
      ],
      "metadata": {
        "id": "vnG5aC6ekXeu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **BERTopic coherence score**"
      ],
      "metadata": {
        "id": "sO7nj4sKER-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bertopic_coherence(model, topics, docs):\n",
        "    # preprocess Documents\n",
        "    documents = pd.DataFrame({\"Document\": docs,\n",
        "                          \"ID\": range(len(docs)),\n",
        "                          \"Topic\": topics})\n",
        "    documents_per_topic = documents.groupby(['Topic'], as_index=False).agg({'Document': ' '.join})\n",
        "    cleaned_docs = model._preprocess_text(documents_per_topic.Document.values)\n",
        "\n",
        "    # extract vectorizer and analyzer from BERTopic\n",
        "    vectorizer = model.vectorizer_model\n",
        "    analyzer = vectorizer.build_analyzer()\n",
        "\n",
        "    # extract features for Topic Coherence evaluation\n",
        "    tokens = [analyzer(doc) for doc in cleaned_docs]\n",
        "    dictionary = Dictionary(tokens)\n",
        "    corpus = [dictionary.doc2bow(token) for token in tokens]\n",
        "    topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
        "               for topic in range(len(set(topics))-1)]\n",
        "\n",
        "    # evaluate\n",
        "    coherence_model = CoherenceModel(topics=topic_words, \n",
        "                                 texts=tokens, \n",
        "                                 corpus=corpus,\n",
        "                                 dictionary=dictionary, \n",
        "                                 coherence='c_v')\n",
        "    return coherence_model.get_coherence()"
      ],
      "metadata": {
        "id": "4i-8_eIQDWMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Coeherence score: {get_bertopic_coherence(topic_model, topics, docs)}\")"
      ],
      "metadata": {
        "id": "bGCBVYq7EX8h",
        "outputId": "8dcde9f4-b34a-49df-8d65-910d7ce003a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coeherence score: 0.5140020610852358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Extracting Topics**"
      ],
      "metadata": {
        "id": "GimKIMmaRZSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the most frequent topics\n",
        "freq = topic_model.get_topic_info()\n",
        "\n",
        "# Show the top 5 most frequent topics\n",
        "freq.head(5)"
      ],
      "metadata": {
        "id": "JIrBNmF-Rcf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The table above shows the five most freqeuente topics and the words present on it extract by BERTopic. -1 refers to all outliers and should be ignored."
      ],
      "metadata": {
        "id": "TVWcfF5mRrMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# show the most frequent topic\n",
        "topic_model.get_topic(0)"
      ],
      "metadata": {
        "id": "Br_UMf1kRxU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** BERTopic is stocastich which means that the topics might differ across runs this is mostly due to the stocastisch nature of UMAP"
      ],
      "metadata": {
        "id": "YpP4HgF2R6Wa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Save topic info table as CSV**"
      ],
      "metadata": {
        "id": "CxWLChzJlPmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to save \n",
        "path = WORK_DIR + f'results/{DATA_FRAME_FEATURE_NAME}/topic_info_tables/'\n",
        "\n",
        "# Use makedirs() to create a new directory if it does not exists\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)\n",
        "\n",
        "# Save table as csv\n",
        "freq.head(10).to_csv(path + 'topic_info_preprocessed_lemma.csv', index=False)"
      ],
      "metadata": {
        "id": "9wM4Ymh_lOdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualization**"
      ],
      "metadata": {
        "id": "wBsA8hiVSJDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Intertopic Distance Map**\n",
        "\n",
        "This graph shows the distance intertopic and help us understand the promixity of topics"
      ],
      "metadata": {
        "id": "2twooZDXUc2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = topic_model.visualize_topics(width=800, height=800)\n",
        "fig"
      ],
      "metadata": {
        "id": "Ae2JSAENSIOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Save intertopic distance map**"
      ],
      "metadata": {
        "id": "VEy11A_SlliP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to save \n",
        "path = WORK_DIR + f'results/{DATA_FRAME_FEATURE_NAME}/intertopic_distance_map/'\n",
        "\n",
        "# Use makedirs() to create a new directory if it does not exists\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)\n",
        "\n",
        "\n",
        "fig.write_image(path + \"idm_preprocessed_lemma.png\", format=\"png\")\n",
        "fig.write_html(path + \"idm_preprocessed_lemma.html\")"
      ],
      "metadata": {
        "id": "hLy_Eeu4lqCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Github link](https://github.com/punkmic/Topic-Modeling-Reclame-Aqui/blob/master/results/intertopic_distance_map/idm_preprocessed_lemma.png?raw=true)"
      ],
      "metadata": {
        "id": "Jf-iwAsQoOCs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Visualize Topic Hierarchy**\n",
        "\n",
        "The topics that were created can be hierarchically reduced. This visualization shows how the topics relate to one another."
      ],
      "metadata": {
        "id": "r-5bT7AgSgsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = topic_model.visualize_hierarchy(top_n_topics=30, width=800, height=800)\n",
        "fig"
      ],
      "metadata": {
        "id": "TEoOpDD6S4D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Save Hierarchical Clustering**"
      ],
      "metadata": {
        "id": "CyM_L5c6pBXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to save \n",
        "path = WORK_DIR + f'results/{DATA_FRAME_FEATURE_NAME}/hierarchical_clustering/'\n",
        "\n",
        "# Use makedirs() to create a new directory if it does not exists\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)\n",
        "\n",
        "\n",
        "fig.write_image(path + \"hc_preprocessed_lemma.png\", format=\"png\")"
      ],
      "metadata": {
        "id": "CHYmk_TZpHPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Github link](https://github.com/punkmic/Topic-Modeling-Reclame-Aqui/blob/master/results/hierarchical_clustering/hc_preprocessed_lemma.png?raw=true)"
      ],
      "metadata": {
        "id": "VrqyRupApBx1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Visualize Terms**\n",
        "\n",
        "We can visualize the selected terms for a few topics by creating bar charts out of the c-TF-IDF scores for each topic representation."
      ],
      "metadata": {
        "id": "uC26Cc-6UvYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = topic_model.visualize_barchart(top_n_topics=12, width=300, height=300)\n",
        "fig"
      ],
      "metadata": {
        "id": "-NoMSyeWVF2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Save Top Word Scores Bar Chart**"
      ],
      "metadata": {
        "id": "MZWFicVqpWUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to save \n",
        "path = WORK_DIR + f'results/{DATA_FRAME_FEATURE_NAME}/top_words_scores/'\n",
        "\n",
        "# Use makedirs() to create a new directory if it does not exists\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)\n",
        "\n",
        "\n",
        "fig.write_image(path + \"tws_preprocessed_lemma.png\", format=\"png\")"
      ],
      "metadata": {
        "id": "Qrz2ywMapdO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Github link](https://github.com/punkmic/Topic-Modeling-Reclame-Aqui/blob/master/results/top_words_scores/tws_preprocessed_lemma.png?raw=true)"
      ],
      "metadata": {
        "id": "HtFLmwl4pTAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Visualize Topic Similarity**\n",
        "\n",
        "This plot shows a similarity matrix by simply applying cosine similarities through those topic embeddings generate by BERTopic through both c-TF-IDF and embeddings. This matrix indicate how similar certain topics are to each other."
      ],
      "metadata": {
        "id": "qMjOvmYVVUDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = topic_model.visualize_heatmap(n_clusters=20, width=800, height=800)\n",
        "fig"
      ],
      "metadata": {
        "id": "_GL5qZ0nV3M2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Save Similarity Matrix**"
      ],
      "metadata": {
        "id": "CF3QJy6epmQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to save \n",
        "path = WORK_DIR + f'results/{DATA_FRAME_FEATURE_NAME}/similarity_matrix/'\n",
        "\n",
        "# Use makedirs() to create a new directory if it does not exists\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)\n",
        "\n",
        "\n",
        "fig.write_image(path + \"sm_preprocessed_lemma.png\", format=\"png\")"
      ],
      "metadata": {
        "id": "VQOAZurPprA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Github link](https://github.com/punkmic/Topic-Modeling-Reclame-Aqui/blob/master/results/similarity_matrix/sm_preprocessed_lemma.png?raw=true)"
      ],
      "metadata": {
        "id": "y1pa1kWApYgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Visualize Term Score Decline**\n",
        "\n",
        "Topics are represented by a number of words starting with the best representative word. Each word is represented by a c-TF-IDF score. The higher the score, the more representative a word to the topic is. Since the topic words are sorted by their c-TF-IDF score, the scores slowly decline with each word that is added."
      ],
      "metadata": {
        "id": "vd41xsx7Xhgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = topic_model.visualize_term_rank()\n",
        "fig"
      ],
      "metadata": {
        "id": "Rw1wXTEtX967"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Save Term score decline per Topic**"
      ],
      "metadata": {
        "id": "6UXg4gpFpwZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to save \n",
        "path = WORK_DIR + f'results/{DATA_FRAME_FEATURE_NAME}/term_score_decline_topic/'\n",
        "\n",
        "# Use makedirs() to create a new directory if it does not exists\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)\n",
        "\n",
        "\n",
        "fig.write_image(path + \"tsdp_preprocessed_lemma.png\", format=\"png\")"
      ],
      "metadata": {
        "id": "F5Gppkjpp0hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Github link](https://github.com/punkmic/Topic-Modeling-Reclame-Aqui/blob/master/results/term_socore_decline_topic/tsdp_preprocessed_lemma.png?raw=true)"
      ],
      "metadata": {
        "id": "QERxP9EspLjX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Term search**"
      ],
      "metadata": {
        "id": "AZIV-p12ZMXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find topics that contains blackfriday term\n",
        "similar_topics, similarity = topic_model.find_topics(\"blackfriday\", top_n=5)\n",
        "\n",
        "# Show similar topics\n",
        "similar_topics"
      ],
      "metadata": {
        "id": "pHHayMGRZOob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show a specific topic\n",
        "topic_model.get_topic(64)"
      ],
      "metadata": {
        "id": "2BnwvRotZUya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **\"Hiperparameter optimization\"**"
      ],
      "metadata": {
        "id": "f3Q_mQRNPRhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_documents(model, docs, label):\n",
        "  fig = topic_model.visualize_documents(docs, hide_document_hover=True, hide_annotations=True, width=800, height=800)\n",
        "\n",
        "  # Set the path to save \n",
        "  path = WORK_DIR + f'results/{DATA_FRAME_FEATURE_NAME}/documents_n_topics/'\n",
        "\n",
        "  # Use makedirs() to create a new directory if it does not exists\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "  fig.write_image(path + f\"document_n_topics_trial_{label}.png\", format=\"png\")\n",
        "  fig.write_html(path + f\"document_n_topics_trial_{label}.html\")"
      ],
      "metadata": {
        "id": "O-l1u6wucN1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_topics(model, label):\n",
        "  fig = model.visualize_topics(width=800, height=800)\n",
        "\n",
        "  # Set the path to save \n",
        "  path = WORK_DIR + f'results/{DATA_FRAME_FEATURE_NAME}/intertopic_distance_map/'\n",
        "\n",
        "  # Use makedirs() to create a new directory if it does not exists\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "  fig.write_image(path + f\"intertopic_distance_map_trial_{label}.png\", format=\"png\")\n",
        "  fig.write_html(path + f\"intertopic_distance_map_trial_{label}.html\")"
      ],
      "metadata": {
        "id": "zEr6GcxHZptw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_hierarchy(model, label):\n",
        "  fig = model.visualize_hierarchy(width=800, height=800)\n",
        "\n",
        "  # Set the path to save \n",
        "  path = WORK_DIR + f'results/{DATA_FRAME_FEATURE_NAME}/hierarchical_clustering/'\n",
        "\n",
        "  # Use makedirs() to create a new directory if it does not exists\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "  fig.write_image(path + f\"hierarchical_clustering_trial_{label}.png\", format=\"png\")\n",
        "  fig.write_html(path + f\"hierarchical_clustering_trial_{label}.html\")"
      ],
      "metadata": {
        "id": "9XqbXn0KZ3r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_top_words_scores(model, label):\n",
        "  fig = model.visualize_barchart(top_n_topics=12, width=300, height=300)\n",
        "\n",
        "  # Set the path to save \n",
        "  path = WORK_DIR + f'results/{DATA_FRAME_FEATURE_NAME}/top_words_scores/'\n",
        "\n",
        "  # Use makedirs() to create a new directory if it does not exists\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "  fig.write_image(path + f\"top_words_scores_trial_{label}.png\", format=\"png\")\n",
        "  fig.write_html(path + f\"top_words_scores_trial_{label}.html\")"
      ],
      "metadata": {
        "id": "A_21t9rmZ4Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_similarity_matrix(model, label):\n",
        "  fig = model.visualize_heatmap()\n",
        "\n",
        "  # Set the path to save \n",
        "  path = WORK_DIR + f'results/{DATA_FRAME_FEATURE_NAME}/similarity_matrix/'\n",
        "\n",
        "  # Use makedirs() to create a new directory if it does not exists\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "  fig.write_image(path + f\"similarity_matrix_trial_{label}.png\", format=\"png\")\n",
        "  fig.write_html(path + f\"similarity_matrix_trial_{label}.html\")"
      ],
      "metadata": {
        "id": "lTV5l7q7Z45m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_term_rank(model, label):\n",
        "  fig = model.visualize_term_rank(width=800, height=800)\n",
        "\n",
        "  # Set the path to save \n",
        "  path = WORK_DIR + f'results/{DATA_FRAME_FEATURE_NAME}/term_score_decline_topic/'\n",
        "\n",
        "  # Use makedirs() to create a new directory if it does not exists\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "  fig.write_image(path + f\"term_score_trial_{label}.png\", format=\"png\")\n",
        "  fig.write_html(path + f\"term_score_trial_{label}.html\")"
      ],
      "metadata": {
        "id": "Ag4Yv6r2bfeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_hyperparameters(trial_params, label):\n",
        "  # Set the path to save \n",
        "  path = WORK_DIR + f'results/{DATA_FRAME_FEATURE_NAME}/hyperparameters/'\n",
        "\n",
        "  # Use makedirs() to create a new directory if it does not exists\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "  with open(path + f\"hyperparameters_trial_{label}.json\", \"w\") as f:\n",
        "    f.write(json.dumps(trial_params))"
      ],
      "metadata": {
        "id": "3wuSDGh4dxlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_freq_topics(model, label):\n",
        "  # Print the most frequent topics\n",
        "  freq = topic_model.get_topic_info()\n",
        "\n",
        "  # Show the top 5 most frequent topics\n",
        "  freq = freq.head(5)\n",
        "\n",
        "  # Set the path to save \n",
        "  path = WORK_DIR + f'results/{DATA_FRAME_FEATURE_NAME}/frequent_topics/' \n",
        "\n",
        "  # Use makedirs() to create a new directory if it does not exists\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "  freq.to_html(path + f\"freq_topics_trial_{label}.json\")\n",
        "  freq.to_csv(path + f\"freq_topics_trial_{label}.csv\", index=False)"
      ],
      "metadata": {
        "id": "DQcgSa44ZtdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, label):\n",
        "  # save model\n",
        "  path = WORK_DIR + f'results/{DATA_FRAME_FEATURE_NAME}/models/'\n",
        "\n",
        "  # Use makedirs() to create a new directory if it does not exists\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "  model.save(path + label)"
      ],
      "metadata": {
        "id": "lv9hK2GrQhoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_coherence(model, topics, docs, label, clustering_model, reduction_model):\n",
        "  \n",
        "  # compute coherence score for BERTopic\n",
        "  coherence_score = get_bertopic_coherence(model, topics, docs)\n",
        "  print(f\"Bertopic Coeherence score: {coherence_score}\")\n",
        "\n",
        "  # save scores\n",
        "  path = WORK_DIR + f'results/{DATA_FRAME_FEATURE_NAME}/coherence/'\n",
        "\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "  with open(path + 'coherence_scores.csv', 'a', newline='') as f:\n",
        "    fieldnames = ['model', 'clustering', 'reduction', 'coherence_score']\n",
        "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "    data = [{'model': label,\n",
        "             'clustering': clustering_model, \n",
        "             'reduction': reduction_model,\n",
        "             'coherence_score': round(coherence_score, 4)}]\n",
        "    writer.writerows(data)"
      ],
      "metadata": {
        "id": "MkxTHUdDPuIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the number of models to generate by optuna\n",
        "NUMBER_OF_MODELS = 30"
      ],
      "metadata": {
        "id": "ZcAm5WqZxLnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimizer(trial):\n",
        "\n",
        "  clustering_option = trial.suggest_categorical('clustering_algorithm__name', ['HDBSCAN', 'K-means'])\n",
        "  dimensionality_option = trial.suggest_categorical('reduction_algorithm__name', ['UMAP', 'PCA'])\n",
        "\n",
        "  # BERTopic hyperparameters\n",
        "  top_n_words = trial.suggest_int('bertopic__top_n_words', 5, 14)\n",
        "  n_gram_range = ast.literal_eval(trial.suggest_categorical('bertopic__n_gram_range', ['(1,1)', '(1,2)', '(1,3)']))\n",
        "  min_topic_size = trial.suggest_int('bertopic__min_topic_size', 15, 20)\n",
        "  diversity = trial.suggest_float('bertopic__diversity', 0.1, 1.0)\n",
        "  outlier_threshold = trial.suggest_float('bertopic__outliers_threshold', 0.04, 0.09)\n",
        "  nr_topics = trial.suggest_int('bertopic__nr_topics', 6, 20, step=1)\n",
        "\n",
        "  if clustering_option == 'HDBSCAN':\n",
        "    # HDBSCAN hyperparameters\n",
        "    min_cluster_size = trial.suggest_int('hdbscan__min_cluster_size', 10, 14)\n",
        "    cluster_selection_epsilon = trial.suggest_float('hdbscan__cluster_selection_epsilon', 0.1, 1.0)\n",
        "\n",
        "    # create a new HDBSCAN model to cluster documents\n",
        "    clustering_model = HDBSCAN(min_cluster_size=min_cluster_size, prediction_data=True)\n",
        "  elif clustering_option == 'K-means':\n",
        "    # K-means hyperparameters\n",
        "    k_means_n_clusters = trial.suggest_int('k-means__n_cluster',6, 10)\n",
        "\n",
        "    # create a new HDBSCAN model to cluster documents\n",
        "    clustering_model = KMeans(n_clusters=k_means_n_clusters)\n",
        "\n",
        "\n",
        "  if dimensionality_option == 'UMAP':\n",
        "    \n",
        "    # UMAP hyperparameters\n",
        "    n_neighbors = trial.suggest_int('umap__n_neighbors', 13, 17)\n",
        "    n_components = trial.suggest_int('umap__n_components', 2, 8)\n",
        "    metric = trial.suggest_categorical('umap__metric', ['cosine', 'euclidean'])\n",
        "    min_dist = trial.suggest_float('umap__min_dist', 0.1, 1.0)\n",
        "    spread = trial.suggest_float('umap__spread', 0.1, 1.0)\n",
        "\n",
        "    # create a new UMAP model to reduce dimension\n",
        "    reduction_model = UMAP(n_neighbors=n_neighbors, metric=metric, random_state=42)\n",
        "  elif dimensionality_option == 'PCA':\n",
        "    \n",
        "    # PCA hyperparameters\n",
        "    pca_n_components = trial.suggest_int('pca__n_components', 4, 6)\n",
        "    \n",
        "    # create a new PCA model to reduce dimension\n",
        "    reduction_model = PCA(n_components=pca_n_components, random_state=12) # k-Means, that does not produce any outliers at all\n",
        "\n",
        "\n",
        "  # CountVectorizer hyperparameters \n",
        "  max_features = trial.suggest_int('vectorizer__max_features', 3000, 6000)\n",
        "\n",
        "  # reduce the impact of frequent words.\n",
        "  ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
        "\n",
        "  # list of portuguese stop words + custom words\n",
        "  stop_words = nltk.corpus.stopwords.words('portuguese') + custom_stop_words\n",
        "\n",
        "  # create a new CountVectorizer to create a matrix of tokens count\n",
        "  vectorizer_model = CountVectorizer(stop_words=stop_words, ngram_range=n_gram_range, max_features=max_features)\n",
        "\n",
        "\n",
        "  # create a new BERTopic model using multilingual option\n",
        "  model = BERTopic(language=\"multilingual\", \n",
        "                   nr_topics=nr_topics,\n",
        "                   calculate_probabilities=True, \n",
        "                   verbose=False,\n",
        "                   top_n_words=top_n_words,\n",
        "                   n_gram_range=n_gram_range,\n",
        "                   min_topic_size=min_topic_size,\n",
        "                   diversity=diversity,\n",
        "                   umap_model=reduction_model,\n",
        "                   hdbscan_model=clustering_model,\n",
        "                   vectorizer_model=vectorizer_model,\n",
        "                   ctfidf_model=ctfidf_model)\n",
        "  \n",
        "  try:\n",
        "    label = trial.number\n",
        "    params = trial.params\n",
        "  \n",
        "    # define model id\n",
        "    model_id = f\"model_trial_{label}\"\n",
        "\n",
        "    # train BERTopic model \n",
        "    topics, probs = model.fit_transform(docs)\n",
        "\n",
        "    # save plots\n",
        "    save_topics(model, label)\n",
        "    save_documents(model, docs, label)\n",
        "    save_hierarchy(model, label)\n",
        "    save_term_rank(model, label)\n",
        "    save_top_words_scores(model, label)\n",
        "  \n",
        "    # save model\n",
        "    save_model(model, model_id)\n",
        "\n",
        "    # save hyperparameters\n",
        "    save_hyperparameters(params, label)\n",
        "\n",
        "    # save model coherence score\n",
        "    save_coherence(model, \n",
        "                   topics,\n",
        "                   docs,\n",
        "                   model_id,\n",
        "                   clustering_option,\n",
        "                   dimensionality_option)\n",
        "    \n",
        "  except Exception as error:\n",
        "    print(error)\n",
        "  \n",
        "  return 0.0"
      ],
      "metadata": {
        "id": "O87BZ5kyQEvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# create a new study\n",
        "study = optuna.create_study(study_name='Bertopic')\n",
        "\n",
        "# run the optmize function \n",
        "study.optimize(optimizer, n_trials=NUMBER_OF_MODELS)"
      ],
      "metadata": {
        "id": "57mnK6MfYAp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Merge of similar topics**"
      ],
      "metadata": {
        "id": "kmSbzWH0gJHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: select the best model and merge similar topic and save final model\n",
        "\n",
        "#topic_model = BERTopic.load(\"best_model\")"
      ],
      "metadata": {
        "id": "OWI9jDFYgTLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Github**"
      ],
      "metadata": {
        "id": "F0gliNtXRkfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! ssh-keygen -t rsa -b 4096\n",
        "# Add github.com to our known hosts\n",
        "! ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts\n",
        "# Restrict the key permissions, or else SSH will complain.\n",
        "! chmod go-rwx /root/.ssh/id_rsa"
      ],
      "metadata": {
        "id": "yVd1eoa0zK7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat /root/.ssh/id_rsa.pub"
      ],
      "metadata": {
        "id": "_z-PSHRzz0PY",
        "outputId": "7db5cdac-5efd-4691-8e2f-2e3056829c6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQC6/NSF77pXXyhyr6o4XWk+9GTfR4W9zDbFgE1LNVOeaGaAwmPJt1l8wjPZnhr703WVXXMCDsHqBxQfDLcnODYCkjpFBQrtwJOH5xTWtfTRkidyjz9jrA1zgNcl2TEoHS4DCWgaANiUvaC/lgq2hvaJ8/EvQmZrzSodkmlNONRomLLkiSbvpYBF6a5q77KOwvb4m3H28WT8DC/sptgc3j6ns5x3Zv9wYdl1Zl8XtjPWxeSVGyLqWwjWQ0exL32SQPSJTnShtGDvqdfvOmLBT6jBQLOvNeoJFIoxbcO+pZpiMlCbKPOnT4QsWaVyI/7zXJ+cougquqN2yUVlsp6RxFnnpexijw88jicUb3JAPc9DYu4CqQQ71NPmB9r8lGTncTPhECmcFwxpq42wzKNX97a28L1UJ6u4cCajMVG+LXe/n0mxP9nmOSGaPdQl6pHz9EJOp1f7wUv0svlRl4ulFelL61KDWe5i2ZX2bKidFP8KKGbH5dpVTy7+WnnPIFTUTrNt2KyBrV0uwwlxpdRx889hU9n7D8QAhsuCcoL+I1QaWFl29F5BvE0McjoG3V+RtGwPrxZUTpEv0Hf6AibjwExAVze0TDz0gK4hl+9ywXrJ+6/4Y/D0oxnncS0F8qMHlBoIj8KFe8XMUwMoyksmM544+2C4BDngtAodDGEhRfG45Q== root@d8d881f9a738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"mattheus_ribeiro@outlook.com\"\n",
        "!git config --global user.name \"punkmic\""
      ],
      "metadata": {
        "id": "4iixpGcjzxrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ssh -T git@github.com"
      ],
      "metadata": {
        "id": "bcqhgkdaz3QI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751d82dc-5c9d-4bcc-eb52-b65ac5140e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Permanently added the RSA host key for IP address '140.82.121.4' to the list of known hosts.\r\n",
            "Hi punkmic! You've successfully authenticated, but GitHub does not provide shell access.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone git@github.com:punkmic/Topic-Modeling-Reclame-Aqui.git"
      ],
      "metadata": {
        "id": "zSA4ju5NDpqK",
        "outputId": "5bac3e11-099d-4d81-bb87-db15d800866b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Topic-Modeling-Reclame-Aqui'...\n",
            "remote: Enumerating objects: 16308, done.\u001b[K\n",
            "remote: Counting objects: 100% (2127/2127), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1859/1859), done.\u001b[K\n",
            "Receiving objects: 100% (16308/16308), 127.24 MiB | 8.43 MiB/s, done.\n",
            "remote: Total 16308 (delta 323), reused 1950 (delta 234), pack-reused 14181\u001b[K\n",
            "Resolving deltas: 100% (1471/1471), done.\n",
            "Checking out files: 100% (14808/14808), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Topic-Modeling-Reclame-Aqui/"
      ],
      "metadata": {
        "id": "2eEK0j1L6b7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ./results/documents"
      ],
      "metadata": {
        "id": "CGqBhuS6z7WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "id": "eyMFQF889jtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Adding preprocessed BERTopic result\""
      ],
      "metadata": {
        "id": "PFY8B1Ikz-U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin master"
      ],
      "metadata": {
        "id": "uEJWirD70EiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run this command to push a new version of this notebook in case you have saved the notebook in github and it is outdate \n",
        "!git stash\n",
        "!git pull\n",
        "!git stash pop"
      ],
      "metadata": {
        "id": "pKF8mcLoIU3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /root/.ssh/"
      ],
      "metadata": {
        "id": "awCNnf2Qlu_5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}